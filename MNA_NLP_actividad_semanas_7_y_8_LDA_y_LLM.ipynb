{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaramillo35/Natural-Language-Processing/blob/main/MNA_NLP_actividad_semanas_7_y_8_LDA_y_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hVND8xY2OKY"
      },
      "source": [
        "# **Procesamiento de Lenguaje Natural**\n",
        "\n",
        "## Maestría en Inteligencia Artificial Aplicada\n",
        "#### Tecnológico de Monterrey\n",
        "#### Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "### **Adtividad en Equipos Semanas 7 y 8 : LDA y LMM audio-a-texto**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aimHVFOv23lm"
      },
      "source": [
        "* **Nombres y matrículas:**\n",
        "\n",
        "  *   Arturo Jain (A01794992)\n",
        "  *   José Ashamat Jaimes Saavedra (A01736690)\n",
        "  *   Owen Jáuregui (A01638122)\n",
        "  *   Ramiro Martin Jaramillo Romero (A01171251)\n",
        "\n",
        "* **Número de Equipo:**\n",
        "\n",
        "  * Equipo 80\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jimvsiVgjMg"
      },
      "source": [
        "* ##### **En cada ejercicio pueden importar los paquetes o librerías que requieran.**\n",
        "\n",
        "* ##### **En cada ejercicio pueden incluir las celdas y líneas de código que deseen.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BtP-Sk0DT-M"
      },
      "source": [
        "# **Ejercicio 1:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh78pKeMghfe"
      },
      "source": [
        "* #### **Liga de los audios de las fábulas de Esopo:** https://www.gutenberg.org/ebooks/21144\n",
        "\n",
        "* #### **Descargar los 10 archivos de audio solicitados: 1, 4, 5, 6, 14, 22, 24, 25, 26, 27.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfs5Zxc9j7Uf",
        "outputId": "790d2382-abb7-4c30-904a-061c50b3e05e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargando https://www.gutenberg.org/files/21144/m4b/21144-01.m4b → audios/fabula_01.m4b\n",
            "Descargando https://www.gutenberg.org/files/21144/m4b/21144-04.m4b → audios/fabula_04.m4b\n",
            "Descargando https://www.gutenberg.org/files/21144/m4b/21144-05.m4b → audios/fabula_05.m4b\n",
            "Descargando https://www.gutenberg.org/files/21144/m4b/21144-06.m4b → audios/fabula_06.m4b\n",
            "Descargando https://www.gutenberg.org/files/21144/m4b/21144-14.m4b → audios/fabula_14.m4b\n",
            "Descargando https://www.gutenberg.org/files/21144/m4b/21144-22.m4b → audios/fabula_22.m4b\n",
            "Descargando https://www.gutenberg.org/files/21144/m4b/21144-24.m4b → audios/fabula_24.m4b\n",
            "Descargando https://www.gutenberg.org/files/21144/m4b/21144-25.m4b → audios/fabula_25.m4b\n",
            "Descargando https://www.gutenberg.org/files/21144/m4b/21144-26.m4b → audios/fabula_26.m4b\n",
            "Descargando https://www.gutenberg.org/files/21144/m4b/21144-27.m4b → audios/fabula_27.m4b\n"
          ]
        }
      ],
      "source": [
        "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
        "# Descargamos las fabulas del proyecto Gutenberg\n",
        "# Obtenemos 10 audios en especifico (ids) y las guardamos de forma local\n",
        "\n",
        "import os\n",
        "from urllib import request\n",
        "\n",
        "# Lista de IDs a descargar\n",
        "ids = [1, 4, 5, 6, 14, 22, 24, 25, 26, 27]\n",
        "\n",
        "# Ahora usamos la ruta .m4b en Gutenberg\n",
        "base_url = \"https://www.gutenberg.org/files/21144/m4b/21144-{id:02d}.m4b\"\n",
        "\n",
        "# Creamos el directorio para guardar los audios\n",
        "os.makedirs(\"audios\", exist_ok=True)\n",
        "\n",
        "# Descargamos los audios y los guardamos en el directorio \"audios\"\n",
        "for i in ids:\n",
        "    url = base_url.format(id=i)\n",
        "    out_path = f\"audios/fabula_{i:02d}.m4b\"\n",
        "    print(f\"Descargando {url} → {out_path}\")\n",
        "    request.urlretrieve(url, out_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uYgtCvvJSmq"
      },
      "source": [
        "# **Ejercicio 2a:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAQjVP2HkoZY"
      },
      "source": [
        "* #### **Comenten el por qué del modelo seleccionado para extracción del texto de los audios.**\n",
        "\n",
        "* #### **Extraer el contenido de los audios en texto.**\n",
        "\n",
        "* #### **Sugerencia:** pueden extraerlo en un formato de diccionario, clave:valor $→$ {audio01:fabula01, ...}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3k5sLGhnO1d",
        "outputId": "76512269-3e55-4194-e30d-1c4e7a4143ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transcribiendo fábula 1 desde fabula_01.m4b…\n",
            "Transcribiendo fábula 22 desde fabula_22.m4b…\n",
            "Transcribiendo fábula 24 desde fabula_24.m4b…\n",
            "Transcribiendo fábula 14 desde fabula_14.m4b…\n",
            "Transcribiendo fábula 25 desde fabula_25.m4b…\n",
            "Transcribiendo fábula 6 desde fabula_06.m4b…\n",
            "Transcribiendo fábula 26 desde fabula_26.m4b…\n",
            "Transcribiendo fábula 4 desde fabula_04.m4b…\n",
            "Transcribiendo fábula 5 desde fabula_05.m4b…\n",
            "Transcribiendo fábula 27 desde fabula_27.m4b…\n"
          ]
        }
      ],
      "source": [
        "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
        "# Usamos pydub para cargar y manipular los audios\n",
        "# Tambien usamos Whisper para transcribir los audios\n",
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "import re\n",
        "from pathlib import Path\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "\n",
        "# 1) Encuentra todos los audios\n",
        "audio_dir = Path(\"audios\")\n",
        "audio_paths = list(audio_dir.glob(\"*.m4b\")) + list(audio_dir.glob(\"*.mp3\"))\n",
        "\n",
        "# 2) Carga el modelo y el procesador\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v2\")\n",
        "model     = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v2\")\n",
        "\n",
        "# Funcion para cargar el audio y lo normalizamos\n",
        "def load_audio(path: Path, target_sr: int = 16_000):\n",
        "    seg = AudioSegment.from_file(str(path))\n",
        "    seg = seg.set_frame_rate(target_sr).set_channels(1)\n",
        "    arr = np.array(seg.get_array_of_samples(), dtype=np.float32)\n",
        "    if seg.sample_width == 2:\n",
        "        arr /= 2**15\n",
        "    return arr, target_sr\n",
        "\n",
        "# Funcion para transcribir el audio\n",
        "def transcribir(path: Path):\n",
        "    # a) Carga y normaliza en memoria\n",
        "    audio, sr = load_audio(path)\n",
        "    # b) Deja que Processor ponga language/task y te devuelva todo\n",
        "    inputs = processor(\n",
        "        audio,\n",
        "        sampling_rate=sr,\n",
        "        return_tensors=\"pt\",\n",
        "        language=\"es\",    # fuerza español\n",
        "        task=\"transcribe\" # no traducción\n",
        "    )\n",
        "    # c) Genera directamente con todos los inputs preparados\n",
        "    tokens = model.generate(**inputs)\n",
        "    # d) Decodifica y devuelve texto\n",
        "    return processor.batch_decode(tokens, skip_special_tokens=True)[0]\n",
        "\n",
        "# 3) Bucle principal\n",
        "# Creamos un diccionario para guardar los textos de los audios\n",
        "textos = {}\n",
        "for ap in audio_paths:\n",
        "    m = re.search(r\"(\\d+)\", ap.stem)\n",
        "    if not m:\n",
        "        continue\n",
        "    fid = int(m.group(1))\n",
        "    print(f\"Transcribiendo fábula {fid} desde {ap.name}…\")\n",
        "    textos[fid] = transcribir(ap)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW-oa1rp8Aw7"
      },
      "source": [
        "Por qué Whisper:\n",
        "\n",
        "* Multilingüe con alta calidad en español.\n",
        "* Fácil integración con Transformers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM0D83j8EWiN"
      },
      "source": [
        "# **Ejercicio 2b:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiFG5q88EYHU"
      },
      "source": [
        "* #### **Eliminar el inicio y final comunes de los textos extraídos de cada fábula.**\n",
        "\n",
        "* #### **Sugerencia:** Pueden guardar esta información en un archivo tipo JSON, para que al estar probando diferentes opciones en los ejercicios siguientes, puedan recuperar rápidamente la información de cada video/fábula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkbeTmeon_RP"
      },
      "outputs": [],
      "source": [
        "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
        "\n",
        "import re\n",
        "\n",
        "def limpiar_encabezado_pie(texto):\n",
        "    # Eliminamos todo hasta la primera ocurrencia de \"fábula número\"\n",
        "    texto = re.sub(r\"^.*?fábula número \\d+\\s*[:\\-–]?\", \"\", texto, flags=re.IGNORECASE)\n",
        "    # Eliminamos desde \"fin de la fábula\" hasta el final\n",
        "    texto = re.sub(r\"fin de la fábula.*$\", \"\", texto, flags=re.IGNORECASE|re.DOTALL)\n",
        "    return texto.strip()\n",
        "\n",
        "for i in textos:\n",
        "    textos[i] = limpiar_encabezado_pie(textos[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PKaB_Ge0Shc"
      },
      "source": [
        "# **Ejercicio 3:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNrqcQFe0VWR"
      },
      "source": [
        "* #### **Apliquen el proceso de limpieza que consideren adecuado.**\n",
        "\n",
        "* #### **Justifiquen los pasos de limpieza utilizados. Tomen en cuenta que el texto extraído de cada fábula es relativamente pequeño.**\n",
        "\n",
        "* #### **En caso de que decidan no aplicar esta etapa de limpieza, deberán justificarlo.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqwiCCdpq8D_"
      },
      "outputs": [],
      "source": [
        "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
        "\n",
        "# Funcion para limpiar el texto\n",
        "# Convertimos el texto a minusculas\n",
        "# Eliminamos caracteres especiales\n",
        "# Eliminamos espacios en blanco\n",
        "# Devolvemos el texto limpio\n",
        "def limpieza_basica(texto):\n",
        "    texto = texto.lower()\n",
        "    texto = re.sub(r\"[^a-záéíóúüñ\\s]\", \" \", texto)\n",
        "    texto = re.sub(r\"\\s+\", \" \", texto)\n",
        "    return texto.strip()\n",
        "\n",
        "# Limpiamos el texto de los audios (las fábulas)\n",
        "for i in textos:\n",
        "    textos[i] = limpieza_basica(textos[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAr-WKHOFibJ"
      },
      "source": [
        "La única limpieza realizada en este caso fue mantener los caracteres alfabéticos y espacios, eliminando cualquier otro símbolo de puntuación que pudiera haber. Debido a que las herramientas que vamos a usar soportan letras acentuadas, no es necesario sustituirlas. Para evitar tener caracteres sobrantes, también eliminamos espacios innecesarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2ywrmsMP_EF"
      },
      "source": [
        "# **Ejercicio 4:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xFpnt0A0Ub7",
        "outputId": "1624cef0-ac9b-421c-f935-6cc2974baeee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fábula 01: lobo, el, de, un, cabrito, la, casa, por, una, vio…\n",
            "Fábula 04: el, perro, león, en, un, con, se, su, retrocedió, perseguía…\n",
            "Fábula 05: en, que, lo, lobo, de, el, asno, entre, la, sus…\n",
            "Fábula 06: cruz, carnicero, campanilla, el, lobo, en, la, cordero, templo, perro…\n",
            "Fábula 14: sopo, las, fábulas, de, cruz, carnicero, campanilla, el, lobo, en…\n",
            "Fábula 22: cruz, carnicero, campanilla, el, lobo, en, la, cordero, templo, perro…\n",
            "Fábula 24: cruz, carnicero, campanilla, el, lobo, en, la, cordero, templo, perro…\n",
            "Fábula 25: cruz, carnicero, campanilla, el, lobo, en, la, cordero, templo, perro…\n",
            "Fábula 26: el, se, perro, la, de, un, almeja, al, trataba, tragó…\n",
            "Fábula 27: cruz, carnicero, campanilla, el, lobo, en, la, cordero, templo, perro…\n"
          ]
        }
      ],
      "source": [
        "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Supongamos que `textos` es tu dict {id: texto_limpio}\n",
        "# Ordenamos los ids y creamos una lista de documentos\n",
        "ids = sorted(textos)\n",
        "docs = [textos[i] for i in ids]\n",
        "\n",
        "# 1) Vectorizamos (cada fábula es un “documento”)\n",
        "vectorizer = CountVectorizer()\n",
        "dtm = vectorizer.fit_transform(docs)\n",
        "\n",
        "# 2) Creamos un LDA con tantos tópicos como documentos\n",
        "lda = LatentDirichletAllocation(n_components=len(docs), random_state=42)\n",
        "lda.fit(dtm)\n",
        "\n",
        "# 3) Extraemos las 20 palabras más relevantes de cada tópico\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "for topic_idx, comp in enumerate(lda.components_):\n",
        "    top_indices = comp.argsort()[-20:][::-1]\n",
        "    keywords = [terms[i] for i in top_indices]\n",
        "    print(f\"Fábula {ids[topic_idx]:02d}: {', '.join(keywords[:10])}…\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blrrs1sWwkSx"
      },
      "source": [
        "# **Ejercicio 5a y 5b:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWvzQ-aNwsVk"
      },
      "source": [
        "* #### **5a: Mediante el LLM que hayan seleccionado, generar un único enunciado que describa o resuma cada fábula.**\n",
        "\n",
        "* #### **5b: Mediante el LLM que hayan seleccionado, generar tres posibles enunciados diferentes relacionados con la historia de la fábula.**\n",
        "\n",
        "* #### **Sugerencia:** En realidad los dos incisos a y b se pueden obtener con un solo prompt que solicite la información y el formato correspondiente para cada una de estas partes. Por ejemplo, para cada fábula la salida puede ser un primer enunciado genérico que resume o describe dicha temática; seguido de tres enunciados, cada uno hablando sobre una situación o parte diferente de la fábula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9UkVPxM0Xii",
        "outputId": "d9f5548d-bab6-41a0-a05b-32593672973a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando fábula 01 con gpt-4.1…\n",
            "Procesando fábula 04 con gpt-4.1…\n",
            "Procesando fábula 05 con gpt-4.1…\n",
            "Procesando fábula 06 con gpt-4.1…\n",
            "Procesando fábula 14 con gpt-4.1…\n",
            "Procesando fábula 22 con gpt-4.1…\n",
            "Procesando fábula 24 con gpt-4.1…\n",
            "Procesando fábula 25 con gpt-4.1…\n",
            "Procesando fábula 26 con gpt-4.1…\n",
            "Procesando fábula 27 con gpt-4.1…\n",
            "\n",
            "Fábula 01:\n",
            "{\n",
            "  \"resumen\": \"Un lobo intentó atacar a un cabrito que estaba seguro dentro de un corral, pero el cabrito aprovechó la protección para burlarse e insultar al lobo sin miedo.\",\n",
            "  \"subtemas\": [\n",
            "    \"El valor de la seguridad y la protección frente al peligro.\",\n",
            "    \"La valentía puede depender de las circunstancias y no solo del carácter.\",\n",
            "    \"No es prudente insultar o provocar a otros solo porque estamos en una posición segura.\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "Fábula 04:\n",
            "{\n",
            "  \"resumen\": \"Un perro perseguía a un león rugiendo, pero, atemorizado cuando el león se volvió, retrocedió rápidamente y abandonó la persecución.\",\n",
            "  \"subtemas\": [\n",
            "    \"El valor real solo se prueba cuando enfrentamos aquello que tememos.\",\n",
            "    \"No siempre quienes aparentan valentía están dispuestos a afrontar las consecuencias.\",\n",
            "    \"Juzgar las propias capacidades antes de desafiar a alguien más fuerte puede evitar situaciones peligrosas.\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "Fábula 05:\n",
            "{\n",
            "  \"resumen\": \"Un lobo fue a casa de un asno para que repartiese los bienes entre sus compañeros según la ley, pero la avaricia y el egoísmo impidieron un reparto justo.\",\n",
            "  \"subtemas\": [\n",
            "    \"Las consecuencias de la avaricia a la hora de repartir bienes.\",\n",
            "    \"La importancia de la justicia y la equidad en la toma de decisiones.\",\n",
            "    \"Cómo la obediencia a la ley puede verse afectada por los intereses personales.\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "Fábula 06:\n",
            "{\n",
            "  \"resumen\": \"Un lobo persigue a un cordero hasta la casa de un carnicero, pero al entrar al templo con una campanilla en el cuello, se convierte en su propia perdición al ser descubierto por los perros, mostrando que el reflejo de nuestras acciones puede llevarnos a la cruz.\",\n",
            "  \"subtemas\": [\n",
            "    \"Las malas acciones pueden volverse en contra de quien las comete.\",\n",
            "    \"Buscar refugio en el lugar equivocado puede llevar al desastre.\",\n",
            "    \"La apariencia o el ruido pueden delatar nuestras verdaderas intenciones.\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "Fábula 14:\n",
            "{\n",
            "  \"resumen\": \"En la fábula de Esopo, un lobo hambriento ve su reflejo en el río mientras lleva un cordero robado de una casa cercana, pero su avaricia lo lleva a perderlo todo.\",\n",
            "  \"subtemas\": [\n",
            "    \"La avaricia puede hacer que terminemos perdiendo lo que ya poseemos.\",\n",
            "    \"La tentación de desear lo ajeno a menudo conduce a consecuencias negativas.\",\n",
            "    \"Reflexionar sobre nuestros actos antes de actuar evita errores costosos.\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "Fábula 22:\n",
            "{\n",
            "  \"resumen\": \"Un lobo hambriento, al intentar engañar a un cordero en un templo haciéndose pasar por carnicero, es descubierto por un perro gracias al reflejo en el río y la campanilla que lleva el cordero, frustrando así sus malas intenciones.\",\n",
            "  \"subtemas\": [\n",
            "    \"La astucia puede ser desenmascarada por la vigilancia y la prudencia.\",\n",
            "    \"La apariencia engañosa no siempre logra su objetivo cuando hay señales claras del peligro.\",\n",
            "    \"La protección de los inocentes es posible cuando la comunidad está atenta y unida.\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "Fábula 24:\n",
            "{\n",
            "  \"resumen\": \"Un lobo hambriento, al cruzar un río, ve el reflejo de un cordero en el agua y, engañado por la ilusión, termina en el templo de un carnicero donde un perro vigila la casa, enseñándole una valiosa lección.\",\n",
            "  \"subtemas\": [\n",
            "    \"Las apariencias engañan y pueden llevar a engaños peligrosos.\",\n",
            "    \"La codicia puede llevar a perderlo todo y caer en trampas.\",\n",
            "    \"Debemos reflexionar antes de actuar impulsivamente ante lo que deseamos.\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "Fábula 25:\n",
            "{\n",
            "  \"resumen\": \"Un lobo hambriento intenta engañar a un cordero cerca del templo y, al ver su reflejo en el río, aprende que la avaricia y la astucia pueden llevar a la perdición.\",\n",
            "  \"subtemas\": [\n",
            "    \"La codicia puede hacer que uno pierda lo que ya tiene por querer más.\",\n",
            "    \"A veces los intentos de engañar a otros terminan perjudicando a uno mismo.\",\n",
            "    \"Los lugares sagrados o protegidos, como un templo, pueden ser refugio ante el peligro.\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "Fábula 26:\n",
            "{\n",
            "  \"resumen\": \"Un perro, creyendo que una almeja era un huevo, la tragó y sintió dolor en sus entrañas al desgarrarse, lamentando su error.\",\n",
            "  \"subtemas\": [\n",
            "    \"La importancia de no dejarse engañar por las apariencias.\",\n",
            "    \"Las consecuencias de la avidez y la precipitación al actuar sin pensar.\",\n",
            "    \"Aprender a distinguir lo que verdaderamente nos conviene antes de tomar una decisión.\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "Fábula 27:\n",
            "{\n",
            "  \"resumen\": \"Un lobo hambriento, al ver el reflejo de un cordero en el río cerca de un templo, idea un plan para llevárselo cruzando por la casa de un carnicero y un perro con campanilla, aprendiendo que la codicia y la astucia pueden llevar al peligro.\",\n",
            "  \"subtemas\": [\n",
            "    \"La codicia puede llevarnos a situaciones peligrosas y no deseadas.\",\n",
            "    \"La astucia no siempre basta para superar los obstáculos si no se evalúan bien los riesgos.\",\n",
            "    \"Los lugares sagrados o protegidos, como el templo, pueden brindar refugio incluso ante la amenaza de los más fuertes.\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
        "# Usamos GPT para generar resumenes y subtemas de las fábulas\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "dtm        = vectorizer.fit_transform(docs)\n",
        "lda        = LatentDirichletAllocation(n_components=len(docs), random_state=42)\n",
        "lda.fit(dtm)\n",
        "\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Reconstruir palabras_clave como dict {fábula_id: [kw1, kw2, ...]}\n",
        "palabras_clave = {}\n",
        "for topic_idx, comp in enumerate(lda.components_):\n",
        "    top20_idx = comp.argsort()[-20:][::-1]\n",
        "    keywords  = [terms[i] for i in top20_idx]\n",
        "    palabras_clave[ids[topic_idx]] = keywords\n",
        "\n",
        "# 1) Parámetros de OpenAI\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"TÚ API KEY\")\n",
        "\n",
        "# 2) Modelo que vas a usar\n",
        "MODEL_NAME = \"gpt-4.1\"\n",
        "\n",
        "# 3) Inicializa el dict donde guardarás los resultados\n",
        "resultados = {}\n",
        "\n",
        "# 4) Función para invocar a GPT\n",
        "def generar_resumen_y_subtemas(claves, model=MODEL_NAME):\n",
        "    prompt = f\"\"\"\n",
        "Eres un asistente que, dado este conjunto de palabras clave de una fábula de Esopo: {claves},\n",
        "1) Genera un enunciado que resuma la historia en una sola frase.\n",
        "2) Genera tres subtemas distintos (cada uno en frase) para discusión o moraleja.\n",
        "Devuelve JSON con campos \"resumen\" y \"subtemas\" (lista de 3 strings).\n",
        "\"\"\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "# 5) Llamada para cada fábula\n",
        "import json\n",
        "\n",
        "for fid, claves in palabras_clave.items():\n",
        "    print(f\"Procesando fábula {fid:02d} con {MODEL_NAME}…\")\n",
        "    resultados[fid] = generar_resumen_y_subtemas(claves)\n",
        "\n",
        "# 6) Imprime todos los resultados formateados\n",
        "for fid in sorted(resultados):\n",
        "    print(f\"\\nFábula {fid:02d}:\")\n",
        "    data = json.loads(resultados[fid])\n",
        "    print(json.dumps(data, indent=2, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx-dZSFJz9cK"
      },
      "source": [
        "# **Ejercicio 6:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w3usdaC0BCj"
      },
      "source": [
        "* #### **Incluyan sus conclusiones de la actividad audio-a-texto:**\n",
        "\n",
        "\n",
        "* #### **Conclusiones de la actividad audio-a-texto:**\n",
        "\n",
        "1. La combinación de Whisper para transcripción de audio y GPT-4 para análisis de texto demostró ser muy efectiva. Whisper logró transcribir con precisión las fábulas en español, mientras que GPT-4 pudo generar resúmenes coherentes y extraer moralejas relevantes, mostrando cómo diferentes modelos de IA pueden trabajar en conjunto para procesar y analizar contenido. El uso de IA para la transcripción de audio es un concepto muy común en la actualidad. Su uso extenido en múltiples tipos de aplicaciones muestra su utilidad para la sociedad actual, y esta actividad permite observar la útilidad de la misma.\n",
        "\n",
        "2. El uso de Latent Dirichlet Allocation (LDA) para extraer palabras clave de cada fábula proporcionó una base sólida para el análisis posterior. A pesar de que las fábulas son textos cortos, LDA logró identificar términos relevantes que capturaron la esencia de cada historia. El uso de esta herramienta podría ayudar de forma significativa a clasificar textos usando palabras clave que lo definan. En nuestros resultados podemos observar que también aparecen muchas palabras comunes sin valor agregado. Hacer una limpieza previa para eliminar estas palabras podría mejorar ampliamente los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtB5Q3m41YQ0"
      },
      "source": [
        "# **Fin de la actividad LDA y LMM: audio-a-texto**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1BtP-Sk0DT-M",
        "NM0D83j8EWiN",
        "6PKaB_Ge0Shc",
        "i2ywrmsMP_EF",
        "Blrrs1sWwkSx",
        "gWvzQ-aNwsVk"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}